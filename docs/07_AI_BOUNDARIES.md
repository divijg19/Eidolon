## What Generative AI May and May Not Do

This document defines the **strict boundaries** for generative AI usage in `Eidolon`.

AI is a tool for cognition, not authority.  
If AI is allowed to decide outcomes, `Eidolon` ceases to be a simulation.

This file exists to prevent that.

---

## 1. AI Philosophy

Generative AI in `Eidolon` exists to:
- Interpret situations
- Reason under uncertainty
- Express intent in human terms
- Compress experience into memory

AI does **not** exist to:
- Create reality
- Decide winners
- Override systems
- Protect narrative coherence

The world engine is authoritative.  
AI is advisory.

---

## 2. AI as an Agent Component

AI is not an agent.

AI is a **cognitive subsystem** used by:
- NPC agents
- (Optionally) player-facing assistants

All AI outputs are treated as **proposed intent**, never action.

---

## 3. Permitted AI Responsibilities

AI may be used for the following functions only.

---

### 3.1 Reasoning & Planning

AI may:
- Evaluate an agent’s beliefs
- Weigh competing goals
- Propose plausible next actions
- Suggest priorities

AI may not:
- Guarantee success
- Bypass constraints
- Optimize globally

Reasoning is local and subjective.

---

### 3.2 Dialogue & Expression

AI may:
- Generate dialogue text
- Express emotional tone
- Roleplay consistent personality

Dialogue does not change state unless validated by systems.

---

### 3.3 Memory Summarization

AI may:
- Summarize past experiences
- Compress event sequences
- Attach emotional interpretation

Summaries must be:
- Derived from canonical events
- Stored separately from facts

---

### 3.4 Belief Updating

AI may:
- Propose belief updates
- Interpret new information
- Maintain false beliefs

Beliefs remain subjective and revisable.

---

## 4. Prohibited AI Responsibilities

AI must never:

- Create or destroy resources
- Resolve combat
- Decide economic outcomes
- Alter world time
- Bypass causal locks
- Override validation rules
- Access omniscient world state
- Act without system approval

If AI output cannot be validated deterministically, it is invalid.

---

## 5. Input Constraints

AI input must be:
- Perspective-limited
- Role-consistent
- Time-scoped
- Sanitized

AI never receives:
- Full world state
- Hidden agent data
- Future events
- Global truths

AI knows only what its agent knows.

---

## 6. Output Validation

All AI outputs must be validated by:
- Schema checks
- Resource feasibility
- Rule compliance
- Timing constraints

Invalid output is discarded or corrected.

AI failure must not corrupt the world.

---

## 7. Boundedness and Cost

AI usage is:
- Rate-limited
- Triggered only when needed
- Budget-constrained

NPCs do not “think constantly.”

Thinking has cost.

---

## 8. Model Agnosticism

The architecture must support:
- Model replacement
- Local or remote inference
- Mixed model usage

No design may depend on:
- A specific provider
- A specific prompt format
- Emergent model behavior

Models change. Rules remain.

---

## 9. Failure Handling

If AI fails:
- NPCs default to conservative behavior
- World continues
- No rollback occurs

Silence is preferable to hallucination.

---

## 10. Design Guarantees

These boundaries guarantee:
- Determinism
- Fairness of consequence
- Replaceability
- Long-term maintainability

Any feature that requires AI authority is invalid by definition.

---

## 11. Final Statement

AI in `Eidolon` does not write the story.

It helps agents decide  
**what they believe is worth attempting**.

Reality answers them—  
not the model.
